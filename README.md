# TEXT2AV (Text to Audio and Video)

Welcome to the GitHub repository for TEXT2AV (Text to Audio and Video)! This project aims to develop a machine learning-based system that can convert text to audio and video as per the user's request.

## Abstract

The project focuses on utilizing machine learning techniques to convert text into audio and video formats. It integrates various technologies and models, including ModelsScope for text-to-video generation, Wave2Lip for audio-to-face synchronization, and Google TTS for text-to-audio conversion. The project is named "TEXT2AV" (Text to Audio and Video).

## Motivation

The rapid advancement of technology has increased the demand for multimedia content. People prefer consuming information in audio and video formats rather than reading lengthy texts. Text-to-speech (TTS) technology has made significant progress and finds applications in voice assistants and audiobooks. However, existing TTS systems lacked interactivity and human-like interactions. This project was motivated by the desire to create a TTS model with an avatar that can speak the text provided and synchronize its lip movements, providing a more engaging and realistic experience. Additionally, the project aimed to support multiple languages to cater to a diverse user base.

Moreover, generating high-quality videos directly from text inputs was another motivation for this project. Users often encounter videos that do not meet their specific requirements or contain unnecessary noise. By using diffusion models and GANs, this project aimed to generate high-quality videos at no cost, providing users with customized and visually appealing video content.

## Objective of the Project

The main objectives of the project are as follows:

- Develop a user-friendly platform that converts text to audio and video quickly and efficiently.
- Generate audio output using an avatar with lip sync to enhance the human-like interaction.
- Support multiple languages to cater to a diverse user base.
- Utilize diffusion models and GANs to generate high-quality videos from text inputs.
- Provide a cost-effective solution for generating high-resolution videos.

## Software and Hardware Requirements

Software Requirements:
- Operating System: Windows, Linux, or macOS.
- Python: Version 3.6 or later.
- Deep Learning Framework: PyTorch, TensorFlow, or Keras.
- Libraries: Pillow, NumPy, OpenCV, etc.
- Text-to-Speech (TTS) Engines: Microsoft Azure, Amazon Polly, Google Cloud TTS, etc.
- Face and Lip Sync Software: Wave2Lip, FaceSwap, etc.

Hardware Requirements:
- CPU: An advanced multi-core CPU, such as the Intel Core i7 or higher, is recommended.
- GPU: A CUDA-enabled GPU (e.g., NVIDIA GeForce or Tesla) with at least 4GB of VRAM is recommended for faster training and inference.
- Memory: It is advised to have at least 16GB of RAM.
- Storage: Sufficient storage space is required for storing output audio files, model checkpoints, and training data.

## Requirements Engineering

The requirements engineering process for this project involved gathering, analyzing, and documenting specific requirements. These requirements included:

- Conversion of text to audio using Google TTS and an avatar with lip sync.
- Conversion of text to video using ModelsScope and diffusion models.
- Support for multiple languages in both audio and video outputs.
- Integration of Wave2Lip for audio-to-face synchronization.
- Utilization of deep learning frameworks such as PyTorch, TensorFlow, or Keras.
- Utilization of libraries such as Pillow, NumPy, and OpenCV for image and video processing.
- Compatibility with Windows, Linux, or macOS operating systems.
- Hardware requirements, including an advanced multi-core CPU, CUDA-enabledGPU, sufficient RAM, and storage space.

## Results

To see the results or demos of the TEXT2AV system, you can navigate to the following location:

- [Results.mp4]

Please note that the provided link should lead to the location where you have stored your audio and video files generated using the TEXT2AV system. This will allow users to access and experience the output of the system.

## Contributions

Contributions, suggestions, and bug reports are welcome! If you would like to contribute to this project, please follow the standard GitHub workflow for pull requests. Let's collaborate and make TEXT2AV even more impressive together!

## License

This project is licensed under the MIT License. Feel free to use, modify, and distribute the code to create your own text-to-audio and video projects.

## Acknowledgements

I would like to express my gratitude to the open-source community for their continuous contributions and the creators of the ModelsScope, Wave2Lip, and Google TTS for their exceptional technologies and models. Special thanks to all the resources and tutorials that have helped me in developing this project.

## Contact

If you have any questions or suggestions, feel free to reach out to me. You can find my contact information in the profile or the project's GitHub repository.

Thank you for visiting my GitHub repository and exploring TEXT2AV (Text to Audio and Video) project!
